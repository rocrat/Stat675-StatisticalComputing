\documentclass{article}
\usepackage{fullpage}
\usepackage[colorlinks=TRUE,linkcolor=blue]{hyperref}
\usepackage{upgreek}
\title{STAT 675 HW \#1}
\author{Dominic D LaRoche}

\begin{document}
\maketitle

\begin{itemize}
\item[3.1] The pdf and cdf of the two parameter exponential distribution are:\\
$$f(x)=\lambda e^{-\lambda(x-\eta)}, F(x)=1-e^{-\lambda(x-\eta)}$$
Using the inverse transform method we find the inverse function $F^{-1}(u)$:
$$F^{-1}(u)=\eta + \frac{ln(1-u)}{-\lambda}$$
Then I can create a function to find a random sample of size n:\\
<<exp>>=
set.seed(36)
r.exp<-function(n,lambda,eta){
  u<-runif(n)
  x<-(log(1-u)/(-1*lambda))+eta
  return(x)
}
X<-r.exp(1000,2,3)
#to find theoretical quantiles
n=1000
q<-qexp(ppoints(n),2)+3
@
I can then compare the sample to the theoretical quantiles as in figure \ref{exp}.
\begin{figure}
<<qqplot1,echo=FALSE>>=
qqplot(q,X,xlab="Exponential(2,3)",ylab="Sample",ylim=c(3,6.5),xlim=c(3,6.5))
abline(0,1)
rm(list=ls())
@
\caption{Comparison of the randomly generated and theoretical values of the exponential(2,3) distribution. The line represents perfect correspondence.}
\label{exp}
\end{figure}
\clearpage
\item[3.3]We first find the inverse of the Pareto cdf:
$$F^{-1}(u)=exp\left[-\frac{ln(1-u)}{a}+ln(b)\right], u\geq\frac{1}{b}>0,a>0$$
We then use this to generate random sample from a random uniform sample.\\
<<pareto,message=FALSE>>=
require(VGAM)
r_pareto<-function(n,loc,shape){
  y<-c()
  i<-1
  while(length(y)<n){
    U<-runif(1, min=(1/loc), max=(1))
    x<-exp((-1*log(1-U)/shape)+log(loc))
    if(x>loc){
      y[i]<-x
      i<-i+1
    }
  }
  return(y)
}
x<-r_pareto(1000,2,2)
ppdf<-function(x,a,b){(a*(b^a))/(x^(a+1))}

@
The histogram of the Pareto sample with a density curve from the actual Pareto distribution is in figure \ref{pareto}.
\begin{figure}
<<plotPareto,echo=FALSE>>=
hist(x,xlim=c(2,100),breaks=seq(2,150,2),main="")
curve(ppdf(x,2,2)*1000,xlim=c(2,100),add=T)
rm(list=ls())
@
\caption{Sample from the Pareto generator with the theoretical density overlaid}
\label{pareto}
\end{figure}
\clearpage

\item[3.4] Since I could not find a unique inverse to the Raleigh CDF I will use the accept/reject method.  I will choose $g(y) \sim$ Exponential ($\beta=\sigma^2$).  
$$u< \frac{f(y)}{cg(y)}=\frac{\frac{x}{\sigma^2}e^{-x^2/2\sigma^2}}{\frac{c}{\sigma^2}e^{-x/\sigma^2}}=\frac{xexp(\frac{-x^2-2x}{\sigma^2})}{C}$$
The constant $c$ will change depending on the value of $\sigma$ chosen and therefore it will be useful to have a function which sets $C$ based on $\sigma$.  The maximum of the above function over the support $x\geq0,\sigma>0$ can be determined with some calculus to be:\\
$$x=\frac{\sqrt{1+4\sigma^2}}{2}$$
Several histograms with their associated theoretical modes and the number of random uniform variables required to produce a sample of 1000 are shown in figure \ref{ral}.  As can ebe seen in the above equation this generator becomes increasingly inefficient as $\sigma$ grows.\\  
<<Raleigh>>=
r_ral<-function(n,sigma){
  x<-c()
  i<-1
  j<-1
  s2<-sigma^2
  c<-(1+sqrt(1+4*sigma^2))/2
  while(length(x)<n){
    u<-runif(1)
    y<-rexp(1,rate=(1/(sigma^2)))
    j<-j+1
    if(u<((y*(exp((-1*y^2+2*y)/(2*s2))))/c)){
      x[i]<-y
      i<-i+1
    }
  }
  return(list(x,j))
}
r_2<-r_ral(1000,2)
r_4<-r_ral(1000,4)
r_6<-r_ral(1000,6)
r_8<-r_ral(1000,8)
@
\begin{figure}
<<plotral,echo=FALSE>>=

par(mfrow=c(2,2))
hist(r_2[[1]])
text(y=140,x=6,label="sigma=2, j=2451")
hist(r_4[[1]])
text(y=120,x=10,label="sigma=4, j=4508")
hist(r_6[[1]])
text(y=160,x=15,label="sigma=6, j=6746")
hist(r_8[[1]])
text(y=130,x=21,label="sigma=8, j=8685")
par(mfrow=c(1,1))
rm(list=ls())
@
\caption{Several Raleigh distributions, the expected modes (sigma) and the number of random samples needed to generate 1000 numbers (j).}
\label{ral}
\end{figure}
\clearpage

\item[3.8] If Z $\sim$ Normal$(\mu,\sigma^2)$ then $e^Z\sim$Lognormal($\mu=e^{\mu+(\sigma^2/2)}, \sigma^2=e^{2(\mu+\sigma^2)}-e^{2\mu+\sigma^2})$. Therefore to get a lognormal($\mu,\sigma^2$) we will need to generate a Z$\sim$Normal and return $e^Z$.  Figure \ref{lnorm} shows the random sample generated from a lognormal(0,1) distribution and the theoretical density.\\
<<lognorm>>=
r_lnorm<-function(n,mu,sigma2){
  x<-rnorm(n,mu,sigma2)#mu+sigma2/2,2*(mu+sigma2)+log(1-exp(-sigma2)))
  y<-exp(x)
  return(y)
}
l<-r_lnorm(1000,0,1)
@
\begin{figure}
<<lnormplot,echo=FALSE,fig.height=4>>=
par(mfrow=c(1,2))
hist(l,breaks=(seq(0,40,1)),main="")
curve(dlnorm(x,0,1),xlim=c(0,40))
par(mfrow=c(1,1))
rm(list=ls())
@
\caption(A histogram of the randomly generated lognormal sample and the theoretical density of the same distribution)
\label(lnorm)
\end{figure}

\item[3.9] The rescaled Epanechnikov distribution can be simulated with:
<<Epi>>=
r_ekov<-function(n){
  x<-c()
  i<-1
  while(length(x)<n){
    u1<-runif(1,min=-1,max=1)
    u2<-runif(1,min=-1,max=1)
    u3<-runif(1,min=-1,max=1)
    x[i]<-ifelse(u3>=u2 && u3>=u1,u2,u3)
    i=i+1
  }
  return(x)
}
e<-r_ekov(1000)
@
The histogram and density estimate are shown in figure \ref{epi}.\\
\begin{figure}
<<plotek,echo=FALSE,fig.height=4>>=
par(mfrow=c(1,2))
hist(e,main="")
plot(density(e),main="")
par(mfrow=c(1,1))
rm(list=ls())
@
\caption{Histogram of the randomly generated Epanechnikov distribution and a corresponding density estimate}
\label{epi}
\end{figure}

\item[3.11]  Mixture of Normal(0,1) and Normal(3,1):\\
<<nmix>>=
rlocmix<-function(n,l1,l2,p1){
  loc<-sample(c(l1,l2),size=n,replace=TRUE,prob=c(p1,1-p1))
  x<-rnorm(n,loc,1)
  return(x)
}
m<-rlocmix(1000,0,3,.75)
m2<-rlocmix(1000,0,3,.5)
@
Based on the results of figure \ref{nmix}, and some simple logic, I would conjecture that p near 0 or 1 would produce a unimodal distriution with skew whereas a p near 0.5 would produce a bimodal distribution.\\
\begin{figure}
<<mplot,echo=FALSE,fig.height=4>>=
par(mfrow=c(1,2))
hist(m,prob=TRUE,main="")
lines(density(m))
hist(m2,prob=TRUE,main="")
lines(density(m2))
par(mfrow=c(1,1))
rm(list=ls())
@
\caption{Two normal location mixtures one with p=.75 (left) and one with p=.5 (right).  I would conjecture that p near 0 or 1 would produce a unimodal distriution with skew whereas a p near .5 would produce a bimodal distribution.}
\label{nmix}
\end{figure}

\item[3.12] Continuous mixture of Exponential($\Lambda$) with $\Lambda\sim$Gamma($r,\beta$).\\
<<gmix>>=
lam<-rgamma(1000,shape=2,rate=4)
x<-rexp(1000,rate=lam)
rm(list=ls())
@

\item[3.14] This is taken right from example 3.18, results are in figure \ref{mvplot}:\\
<<mvnormChol>>=
rmvn.Choleski <-
    function(n, mu, Sigma) {
        d <- length(mu)
        Q <- chol(Sigma) 
        Z <- matrix(rnorm(n*d), nrow=n, ncol=d)
        X <- Z %*% Q + matrix(mu, n, d, byrow=TRUE)
        X
    }
    
mu <- c(0,1,2)
Sigma <- matrix(c(1,-.5,.5,-.5,1,-.5,.5,-.5,1),3,3)
X <- rmvn.Choleski(200, mu, Sigma)
@
\begin{figure}
<<pplot,echo=FALSE>>=
pairs(X)
rm(list=ls())
@
\caption{The scatterplot matrix from the multivariable normal sample relfect the covariance matrix ($\Sigma$) used to generate them.}
\label{mvplot}
\end{figure}

\item[3.18]  Simulate the Weishart distribution:\\
<<wrt,message=FALSE>>=
#generate lower triangular N(0,1) matrix T with d=5
T<-matrix(rnorm(15),5,5)
T[upper.tri(T)]<-0
i<-1:5
d<-sqrt(rchisq(length(i),6-i+1))
diag(T)<-d
T#lower triangular matrix of N(0,1)
A<-T%*%t(T)
A
#make symmetric sigma matrix
require(Matrix)
sigma<-forceSymmetric(matrix(c(1,0,0,0,0,.5,1,0,0,0,.5,.5,1,0,0,.5,.5,.5,1,0,.5,.5,.5,.5,1),5,5))
l<-chol(sigma)
x<-t(l)%*%A%*%l
x
rm(list=ls())
@

\item[3.19]  Random symmetric walk, figure \ref{walk} shows the results:\\
<<walk>>=
A<-10
trace<-vector()
i<-1
while(A < 20  && A > 0){
  win<-sample(c(-1,1),size=1,prob=c(.5,.5))
  trace[i]<-A #place the trace before updating A to get A(0)
  A<-A+win
  i<-i+1
}
A
trace
t<-1:length(trace)
@
\begin{figure}
<<walkplot,echo=FALSE>>=
plot(t,trace,type="l",ylab="Amount of Money for Player A",xlab="Number of Coin Flips")
@
\caption{Plot of the random symmetric walk.}
\label{walk}
\end{figure}
\end{itemize}
\end{document}